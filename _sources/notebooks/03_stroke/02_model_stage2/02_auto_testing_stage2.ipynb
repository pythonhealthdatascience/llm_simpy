{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50d6948f-b241-4af3-80a3-014119f29d91",
   "metadata": {},
   "source": [
    "# Automated Model Testing \n",
    "\n",
    "This notebook contains a set of automated tests for the Stroke+Rehab model.  These tests are either pass or fail and no interpretation is needed. A summary of test results is provided at the end of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b82004-6400-4997-895d-d42cee5a58dc",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc9ab123-b54c-4439-9154-9d00a0bbac0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statistics\n",
    "from sim_tools.distributions import Lognormal\n",
    "import pytest\n",
    "import ipytest\n",
    "ipytest.autoconfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa41c993-016c-49d3-8699-d79af9b1a457",
   "metadata": {},
   "source": [
    "## Model Code Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08f4c61d-9b84-45bb-a2b8-d6aec6dadef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from s2_stroke_rehab_model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfd2334-3493-4ba2-802c-9a476015aedb",
   "metadata": {},
   "source": [
    "### Results processing\n",
    "\n",
    "A set of tests to check that the results of a simulated run are processed correctly for the user.\n",
    "\n",
    "We test the processing of:\n",
    "\n",
    "* occupancy frequencies\n",
    "* probability of delay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e11366d5-bd0b-4465-8f98-212040cff775",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.parametrize('values, rel_expected, cum_expected', [\n",
    "                          ([1, 1, 1, 1, 2, 2, 2, 3, 3, 4], \n",
    "                           [0.4, 0.3, 0.2, 0.1], [0.4, 0.7, 0.9, 1.0])\n",
    "])\n",
    "def test_result_processing_1(values, rel_expected, cum_expected):\n",
    "    '''\n",
    "    Test the `calculate_occupancy_frequencies` function works\n",
    "    as expected.\n",
    "\n",
    "    Expected result: relative frequencies and cumulative freqs\n",
    "    are the same as expected values.\n",
    "\n",
    "    Params:\n",
    "    ------\n",
    "    values: list\n",
    "        list of values to test\n",
    "\n",
    "    rel_expected: list\n",
    "        list of floats - expected relative freqs\n",
    "\n",
    "    cum_expected: list\n",
    "        list of floats - expected cumulative freqs\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    bool: does the model pass the test.\n",
    "    '''\n",
    "    rel, cum, unique = calculate_occupancy_frequencies(values)\n",
    "    # use all close to allow for minor floating point differences.\n",
    "    assert (set(rel) == set(rel_expected)) and np.allclose(np.array(cum_expected), cum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81298f3b-4d22-4649-8616-7dab92eedae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.parametrize('relative, cum, p_delay_expected', [\n",
    "                          ([0.4, 0.3, 0.2, 0.1], \n",
    "                           [0.4, 0.7, 0.9, 1.0], [1.0, 0.3/0.7, 0.2/0.9, 0.1/1.0])\n",
    "])\n",
    "def test_result_processing_2(relative, cum, p_delay_expected):\n",
    "    '''\n",
    "    Test the probability of delay is calculated correctly\n",
    "    using the `calculate_prob_delay` function.\n",
    "    \n",
    "    Params:\n",
    "    ------\n",
    "    relative: list\n",
    "        list of floats - relative freqs\n",
    "\n",
    "    cum: list\n",
    "        list of floats - cumulative freqs\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    bool: does the function pass the test.\n",
    "    '''\n",
    "    p_delay = calculate_prob_delay(relative, cum)\n",
    "    # use all close to allow for minor floating point differences.\n",
    "    assert np.allclose(np.array(p_delay_expected), p_delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4306f786-8429-4ccb-9d06-9b419fc5a16f",
   "metadata": {},
   "source": [
    "### Results collection tests\n",
    "\n",
    "Test that the optional results collection processes for the ASU and REHAB models work correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a08cfa3-2c28-4cfa-955e-77aa35e7d2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_collection_test1(audit_interval=1):\n",
    "    '''\n",
    "    Test the model collects acute stroke occupancy every day\n",
    "\n",
    "    Expected result: len(experiment.asu_occupancy) == env.now\n",
    "\n",
    "    Params:\n",
    "    ------\n",
    "    audit_interval: 1\n",
    "        duration of audit.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    bool: does the model pass the test.\n",
    "    '''\n",
    "    # Create the experiment\n",
    "    experiment = Experiment({\n",
    "        'run_length': 365*5,  # Run for 5 years\n",
    "        'trace': False,  # Set to True if you want to see detailed logs\n",
    "        'acute_audit_interval': audit_interval  # Audit interval as specified\n",
    "    })\n",
    "\n",
    "    # Create the simulation environment\n",
    "    env = simpy.Environment()\n",
    "\n",
    "    rehab_unit = RehabilitationUnit(env, experiment)\n",
    "\n",
    "    # Create the AcuteStrokeUnit\n",
    "    asu = AcuteStrokeUnit(env, experiment, rehab_unit)\n",
    "\n",
    "    # modified iteration 21\n",
    "    # start the audit_acute_occupancy to record ASU occupancy at intervals\n",
    "    env.process(experiment.audit_acute_occupancy(env, 1, audit_interval, asu, experiment))\n",
    "\n",
    "    # Run the model - modified iteration 21\n",
    "    asu.run()\n",
    "    env.run(until=experiment.params['results_collection_period'])\n",
    "\n",
    "    print(f\"Number of occupancy audits: {len(experiment.asu_occupancy)}\")\n",
    "    print(f'Simulation time: {env.now}')\n",
    "    \n",
    "    # The number of audits should be equal to the simulation time\n",
    "    # (assuming audit_interval=1 and the first audit happens at time 1)\n",
    "    assert len(experiment.asu_occupancy) == (env.now - 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a01d3834-0847-49fa-ba14-2b43722dd3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_results_collection_2(audit_interval=1):\n",
    "    '''\n",
    "    Test the model collects rehab occupancy every day\n",
    "\n",
    "    Expected result: len(experiment.rehab_occupancy) == env.now - 1\n",
    "\n",
    "    Params:\n",
    "    ------\n",
    "    audit_interval: 1\n",
    "        duration of audit.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    bool: does the model pass the test.\n",
    "    '''\n",
    "    # Create the simulation environment\n",
    "    env = simpy.Environment()\n",
    "\n",
    "    # create experiment\n",
    "    experiment = Experiment()\n",
    "    \n",
    "    rehab_unit = RehabilitationUnit(env, experiment)\n",
    "\n",
    "    # Start the audit process - modified iteration 21\n",
    "    env.process(experiment.audit_rehab_occupancy(env, 1, experiment.params['rehab_audit_interval'], rehab_unit, experiment))\n",
    "    \n",
    "    # Run the model for the default run length in the experiment - modified in iteration 21\n",
    "    env.run(until=experiment.params['results_collection_period'])\n",
    "    \n",
    "    print(f'{len(experiment.rehab_occupancy)=}')\n",
    "    print(f'{env.now=}')\n",
    "    assert len(experiment.rehab_occupancy) == (env.now - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d1807a3-a435-40d0-826a-7d309b470680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_results_collection_system(audit_interval=1):\n",
    "    '''\n",
    "    SYSTEM TEST\n",
    "    \n",
    "    Test REHAB ward occupancy data collected is in a sensible range\n",
    "    when it is connected to the ASU model.\n",
    "    \n",
    "    Expected result: The type collected is int. The values are in \n",
    "    the range in the range 1 to [10-15] with sensible moments.\n",
    "\n",
    "    Expected result: \n",
    "        len(experiment.asu_occupancy) == env.now - 1 AND\n",
    "        len(experiment.rehab_occupancy) == env.now - 1\n",
    "\n",
    "    Params:\n",
    "    ------\n",
    "    audit_interval: 1\n",
    "        duration of audit.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    bool: does the model pass the test.\n",
    "    '''\n",
    "    # Create the simulation environment\n",
    "    env = simpy.Environment()\n",
    "    \n",
    "    # Create an experiment with default parameters\n",
    "    experiment = Experiment()\n",
    "\n",
    "    # Create models\n",
    "    rehab_unit = RehabilitationUnit(env, experiment)\n",
    "    asu = AcuteStrokeUnit(env, experiment, rehab_unit)\n",
    "    \n",
    "    # Start the ASU patient generators for each type of patient\n",
    "    asu.run()\n",
    "    rehab_unit.run()\n",
    "\n",
    "    # Start the audit process - modified iteration 21\n",
    "    env.process(experiment.audit_rehab_occupancy(env, 1, experiment.params['rehab_audit_interval'], rehab_unit, experiment))\n",
    "    env.process(experiment.audit_acute_occupancy(env, 1, experiment.params['acute_audit_interval'], asu, experiment))\n",
    "    \n",
    "    # Run the simulation until the specified run length in the Experiment parameters - modified in iteration 21\n",
    "    env.run(until=experiment.params['results_collection_period'])\n",
    "\n",
    "    # Print info for debug\n",
    "    print(f\"Average rehab occupancy: {sum(experiment.rehab_occupancy) / len(experiment.rehab_occupancy):.2f}\")\n",
    "    print(f\"Maximum rehab occupancy: {max(experiment.rehab_occupancy)}\")\n",
    "    print(f\"Minimum rehab occupancy: {min(experiment.rehab_occupancy)}\")\n",
    "    print(f'{len(experiment.asu_occupancy)=}')\n",
    "    print(f'{len(experiment.rehab_occupancy)=}')\n",
    "    print(f'{env.now=}')\n",
    "\n",
    "    # Test\n",
    "    assert len(experiment.asu_occupancy) == (env.now - 1) and \\\n",
    "           len(experiment.rehab_occupancy) == (env.now - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e51360e-ca1b-4587-8dc6-4eed2d20c1f5",
   "metadata": {},
   "source": [
    "## Mode run tests\n",
    "\n",
    "Here we test that various modes of running the model work correctly.  These include\n",
    "\n",
    "* results collection period\n",
    "* warm-up\n",
    "* single run mode\n",
    "* repeatable results using random number sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5129ab6e-9852-4ac1-ae61-dfdc85a7af6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_results_collection_system(audit_interval=1):\n",
    "    '''\n",
    "    SYSTEM TEST\n",
    "    \n",
    "    Test REHAB ward occupancy data collected is in a sensible range\n",
    "    when it is connected to the ASU model.\n",
    "    \n",
    "    Expected result: The type collected is int. The values are in \n",
    "    the range in the range 1 to [10-15] with sensible moments.\n",
    "\n",
    "    Expected result: \n",
    "        len(experiment.asu_occupancy) == env.now - 1 AND\n",
    "        len(experiment.rehab_occupancy) == env.now - 1\n",
    "\n",
    "    Params:\n",
    "    ------\n",
    "    audit_interval: 1\n",
    "        duration of audit.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    bool: does the model pass the test.\n",
    "    '''\n",
    "   # Create the simulation environment\n",
    "    env = simpy.Environment()\n",
    "    \n",
    "    # Create an experiment with default parameters\n",
    "    experiment = Experiment()\n",
    "\n",
    "    # Create models\n",
    "    rehab_unit = RehabilitationUnit(env, experiment)\n",
    "    asu = AcuteStrokeUnit(env, experiment, rehab_unit)\n",
    "    \n",
    "    # Start the ASU patient generators for each type of patient\n",
    "    asu.run()\n",
    "    rehab_unit.run()\n",
    "\n",
    "    # Start the audit process - modified iteration 21\n",
    "    env.process(experiment.audit_rehab_occupancy(env, 1, experiment.params['rehab_audit_interval'], rehab_unit, experiment))\n",
    "    env.process(experiment.audit_acute_occupancy(env, 1, experiment.params['acute_audit_interval'], asu, experiment))\n",
    "    \n",
    "    # Run the simulation until the specified run length in the Experiment parameters - modified in iteration 21\n",
    "    env.run(until=experiment.params['results_collection_period'])\n",
    "\n",
    "    # Print info for debug\n",
    "    print(f\"Average rehab occupancy: {sum(experiment.rehab_occupancy) / len(experiment.rehab_occupancy):.2f}\")\n",
    "    print(f\"Maximum rehab occupancy: {max(experiment.rehab_occupancy)}\")\n",
    "    print(f\"Minimum rehab occupancy: {min(experiment.rehab_occupancy)}\")\n",
    "    print(f'{len(experiment.asu_occupancy)=}')\n",
    "    print(f'{len(experiment.rehab_occupancy)=}')\n",
    "    print(f'{env.now=}')\n",
    "\n",
    "    # Test\n",
    "    assert len(experiment.asu_occupancy) == (env.now - 1) and \\\n",
    "           len(experiment.rehab_occupancy) == (env.now - 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ebe6da0-d74d-46ed-aac1-fabbe2b96655",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.parametrize('warm_up, audit_interval', [\n",
    "                          (365, 1),\n",
    "                          (1000, 1)\n",
    "])\n",
    "def test_warm_up(warm_up, audit_interval):\n",
    "    '''\n",
    "    Test warm-up works correctly for ASU+REHAB ward occupancy\n",
    "\n",
    "    Expected result: \n",
    "        len(experiment.asu_occupancy) == experiment.results_collection_period \n",
    "        AND len(experiment.rehab_occupancy) == experiment.results_collection_period \n",
    "\n",
    "    Params:\n",
    "    ------\n",
    "    audit_interval: 1\n",
    "        duration of audit.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    bool: does the model pass the test.\n",
    "    '''\n",
    "    # Create the experiment with specified warm-up period\n",
    "    experiment = Experiment({\n",
    "        'warm_up': warm_up,\n",
    "        'acute_audit_interval': audit_interval,\n",
    "        'rehab_audit_interval': audit_interval\n",
    "    })\n",
    "\n",
    "    # Create the simulation environment\n",
    "    env = simpy.Environment()\n",
    "    \n",
    "    # Create models\n",
    "    rehab_unit = RehabilitationUnit(env, experiment)\n",
    "    asu = AcuteStrokeUnit(env, experiment, rehab_unit)\n",
    "    \n",
    "    # Start the ASU patient generators\n",
    "    asu.run()\n",
    "\n",
    "    # Start the REHAB patient generators\n",
    "    rehab_unit.run()\n",
    "\n",
    "    # Start the audit processes\n",
    "    env.process(experiment.audit_acute_occupancy(env, warm_up, audit_interval, asu, experiment))\n",
    "    env.process(experiment.audit_rehab_occupancy(env, warm_up, audit_interval, rehab_unit, experiment))\n",
    "    \n",
    "    # Run the simulation\n",
    "    env.run(until=experiment.warm_up + experiment.params['results_collection_period'])\n",
    "\n",
    "    # Print info for debug\n",
    "    print(f'{len(experiment.asu_occupancy)=}')\n",
    "    print(f'{len(experiment.rehab_occupancy)=}')\n",
    "    print(f'{env.now=}')\n",
    "    print(f'{experiment.params[\"results_collection_period\"]=}')\n",
    "    print(f'{experiment.warm_up + experiment.params[\"results_collection_period\"]=}')\n",
    "\n",
    "    # Test\n",
    "    assert (len(experiment.asu_occupancy) == experiment.params['results_collection_period'] and \n",
    "            len(experiment.rehab_occupancy) == experiment.params['results_collection_period'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1c2392f-bdc7-444b-bf33-dae9c947c34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_single_run():\n",
    "    '''\n",
    "    Test the the single_run function returns a dictionary of \n",
    "    results.\n",
    "\n",
    "    The results dictionary contains the following keys:\n",
    "\n",
    "    'relative_freq_asu'\n",
    "    'prob_delay_asu'\n",
    "    'unique_vals_asu'\n",
    "    'relative_freq_rehab'\n",
    "    'prob_delay_rehab'\n",
    "    'unique_vals_rehab'\n",
    "\n",
    "    Expected result: \n",
    "        len(run_results) == 6 and type(run_results) == dict\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    bool: does the model pass the test.\n",
    "    '''\n",
    "\n",
    "    # a default experiment\n",
    "    default_experiment_params = Experiment()\n",
    "\n",
    "    # run the model\n",
    "    run_results = single_run(default_experiment_params)\n",
    "\n",
    "    print(f\"{run_results['relative_freq_asu']=}\")\n",
    "    \n",
    "    # test\n",
    "    assert len(run_results) == 6 and type(run_results) == dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3aa6e2-ef14-46cf-9eb2-70ff21fc09cf",
   "metadata": {},
   "source": [
    "### Random number set test (ASU only)\n",
    "\n",
    "Test that ASU results are repeated each time the same random number set is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bc6c5c8-7422-44a5-92da-e63e3205649a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.parametrize('random_number_set, print_output', [\n",
    "                          (0, False),\n",
    "                          (1, False),\n",
    "                          (2, False),\n",
    "                          (101, False),\n",
    "                          (42, False),\n",
    "])\n",
    "def test_random_number_set_1(random_number_set, print_output):\n",
    "    '''\n",
    "    Test the the ASU model produces repeatable results. \n",
    "\n",
    "    Compares\n",
    "    min, max, mean of occupancy.\n",
    "    \n",
    "    Expected result: \n",
    "        set(run1) == set(run2)\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    bool: does the model pass the test.\n",
    "    '''\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for i in range(2):\n",
    "        \n",
    "        # Create the simulation environment\n",
    "        env = simpy.Environment()\n",
    "        \n",
    "        # Initialize the Acute Stroke Unit model\n",
    "        experiment = Experiment(random_number_set=random_number_set)\n",
    "    \n",
    "        # Add RU, but do not run the model\n",
    "        rehab_unit = RehabilitationUnit(env, experiment)\n",
    "        \n",
    "        asu = AcuteStrokeUnit(env, experiment, rehab_unit)\n",
    "        \n",
    "        # Start the patient generators\n",
    "        asu.run()\n",
    "    \n",
    "        # Start the audit_acute_occupancy generator function to record ASU occupancy at intervals\n",
    "        env.process(experiment.audit_acute_occupancy(env, 1, 1, asu, experiment))\n",
    "        \n",
    "        # Run the simulation until the specified run length in the Experiment parameters\n",
    "        env.run(until=experiment.params['results_collection_period'])\n",
    "\n",
    "        if print_output: \n",
    "            print(f'Run {i} results:')\n",
    "            print(f'{min(experiment.asu_occupancy)=}')\n",
    "            print(f'{max(experiment.asu_occupancy)=}')\n",
    "            print(f'{statistics.fmean(experiment.asu_occupancy)=}')\n",
    "            print([round(q, 1) for q in statistics.quantiles(experiment.asu_occupancy, n=10)])\n",
    "\n",
    "        results.append(set((min(experiment.asu_occupancy), \n",
    "                            max(experiment.asu_occupancy),\n",
    "                            statistics.fmean(experiment.asu_occupancy))))\n",
    "    \n",
    "    # test\n",
    "    assert results[0] == results[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9f82b40-2ec6-48a7-8583-c59f2e48d110",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.parametrize('random_number_set, print_output', [\n",
    "                          (0, False),\n",
    "                          (1, False),\n",
    "                          (2, False),\n",
    "                          (101, False),\n",
    "                          (42, False),\n",
    "])\n",
    "def test_random_number_set_2(random_number_set, print_output):\n",
    "    '''\n",
    "    Test the the single_run function returns a dictionary of \n",
    "    results.\n",
    "\n",
    "    The results dictionary contains the following keys:\n",
    "\n",
    "    'relative_freq_asu'\n",
    "    'prob_delay_asu'\n",
    "    'unique_vals_asu'\n",
    "    'relative_freq_rehab'\n",
    "    'prob_delay_rehab'\n",
    "    'unique_vals_rehab'\n",
    "\n",
    "    Expected result: \n",
    "        len(run_results) == 6 and type(run_results) == dict\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    bool: does the model pass the test.\n",
    "    '''\n",
    "    \n",
    "    results = []\n",
    "    for i in range(2):\n",
    "    \n",
    "        # set a random number set for streams\n",
    "        experiment = Experiment(random_number_set=random_number_set)\n",
    "    \n",
    "        # run the model\n",
    "        run_results = single_run(experiment)\n",
    "\n",
    "        if print_output: \n",
    "            print(f'Run {i} results:')\n",
    "            print(f'{min(experiment.asu_occupancy)=}')\n",
    "            print(f'{max(experiment.asu_occupancy)=}')\n",
    "            print(f'{statistics.fmean(experiment.asu_occupancy)=}')\n",
    "            print([round(q, 1) for q in statistics.quantiles(experiment.asu_occupancy, n=10)])\n",
    "\n",
    "        results.append(set((min(experiment.asu_occupancy), \n",
    "                            max(experiment.asu_occupancy),\n",
    "                            statistics.fmean(experiment.asu_occupancy))))\n",
    "    \n",
    "    # test\n",
    "    assert results[0] == results[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbc35be-fac1-449f-bbde-d16d280717ff",
   "metadata": {},
   "source": [
    "### Lognormal test\n",
    "\n",
    "Test that lognomal function correctly calculates the moments of the underlying normal dist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f8ae16a-821f-40b1-8167-7375c65eff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.parametrize('mean, std', [\n",
    "                          (128.79, 267.51),\n",
    "                          (50.0, 2.0),\n",
    "                          (10.5, 1.0),\n",
    "])\n",
    "def test_lognormal_moments(mean, std):\n",
    "    '''\n",
    "    Test that lognomal function correctly calculates \n",
    "    the moments of the underlying normal dist.\n",
    "\n",
    "    Params:\n",
    "    ------\n",
    "    mean: float\n",
    "        mean of the lognormal distribution\n",
    "\n",
    "    std: float\n",
    "        st dev of the lognormal distribution\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    bool\n",
    "    '''\n",
    "   \n",
    "    # Lognormal class from sim-tools.\n",
    "    expected_moments = Lognormal(mean, std)\n",
    "    print(expected_moments.mu, expected_moments.sigma)\n",
    "\n",
    "    # Convert lognormal parameters from llm for asu\n",
    "    normal_mean = math.log(mean**2 / math.sqrt(std**2 + mean**2))\n",
    "    normal_std = math.sqrt(math.log(1 + (std**2 / mean**2)))\n",
    "    print(normal_mean, normal_std)\n",
    "\n",
    "    # Check llm lognormal function used in rehab model - changed in iteration 23\n",
    "    normal_mean2 = np.log(mean ** 2 / np.sqrt(std ** 2 + mean ** 2))\n",
    "    normal_std2 = np.sqrt(np.log(std ** 2 / mean ** 2 + 1))\n",
    "    print (normal_mean2, normal_std2)\n",
    "\n",
    "\n",
    "    assert (normal_mean, normal_std) == pytest.approx((expected_moments.mu, expected_moments.sigma)) == (normal_mean2, normal_std2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c955f7-4f58-4cbb-baa5-77af846341b8",
   "metadata": {},
   "source": [
    "### Extreme value tests\n",
    "\n",
    "Extreme value tests are used pragmatically to block of routes/arrivals/activites in the simulation model and check the results.\n",
    "\n",
    "The most simple way to modify the model for these tests is to set parameters to $M$ a very large number.\n",
    "\n",
    "We test\n",
    "\n",
    "* Block all arrivals\n",
    "* Acute LoS is infinite\n",
    "* Block all but stroke->rehab patient arrivals in the ASU.\n",
    "* Block all rehab arrivals apart from stroke.\n",
    "* Block all external rehab arrivals\n",
    "* Rehab LoS is infinite (Rehab model only)\n",
    "* Block all arrivals to the ASU and Rehab models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74b78bdc-8be1-4f85-a58c-71826b5703dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 10_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec28e400-44cd-436d-b224-5952ffba99b4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ev_test_2(large_number=M):\n",
    "    '''\n",
    "    All patient types have their inter-arrival time set to $M$ a very large number.\n",
    "    \n",
    "    Expected result: No patients arrive to the model.\n",
    "    \n",
    "    Params:\n",
    "    -------\n",
    "    large_number: int\n",
    "        M a very large number \n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    int: the number of patients that arrived to the model.\n",
    "    '''\n",
    "    \n",
    "    # Define custom parameters\n",
    "    custom_params = {\n",
    "        'patient_types': {\n",
    "            'Stroke': {'interarrival_time': large_number},\n",
    "            'TIA': {'interarrival_time': large_number},\n",
    "            'Complex Neurological': {'interarrival_time': large_number},\n",
    "            'Other': {'interarrival_time': large_number}\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Create an Experiment instance with custom parameters\n",
    "    experiment = Experiment(custom_params)\n",
    "    \n",
    "    # Run the simulation with the custom experiment\n",
    "    env = simpy.Environment()\n",
    "    rehab_unit = RehabilitationUnit(env, experiment)\n",
    "    model = AcuteStrokeUnit(env, experiment, rehab_unit)\n",
    "    model.run()\n",
    "    env.run(until=experiment.params['results_collection_period'])\n",
    "    \n",
    "    # Print results to check\n",
    "    print(\"\\nSimulation completed.\")\n",
    "    print(f\"Total simulation time: {model.env.now:.2f} days\")\n",
    "    print(f\"Total patient arrivals: {model.total_arrivals}\")\n",
    "    for patient_type in model.patient_types.values():\n",
    "        print(f\"Total {patient_type.name} arrivals: {patient_type.count}\")\n",
    "    \n",
    "    # Return the number of total arrivals\n",
    "\n",
    "    assert model.total_arrivals == 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "367854b4-708f-4672-9031-36eaf91c5e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ev_test_3(large_number=M):\n",
    "    '''\n",
    "    All patient types have have their mean length \n",
    "    of stay time set to $M$ a very large number\n",
    "    \n",
    "    Expected result: No patients depart the model \n",
    "    The number of arrivals = the occupancy of the model.\n",
    "\n",
    "    Params:\n",
    "    -------\n",
    "    large_number: int\n",
    "        M a very large number \n",
    "    '''\n",
    "    \n",
    "    # Define custom parameters\n",
    "    custom_params = {\n",
    "        'Stroke': {'Rehab': (large_number, 8.6), 'ESD': (large_number, 4.8), 'Other': (large_number, 8.7)},\n",
    "        'TIA': (large_number, 5.0),\n",
    "        'Complex Neurological': (large_number, 5.0),\n",
    "        'Other': (large_number, 5.2)\n",
    "    }\n",
    "    \n",
    "    # Create an Experiment instance with custom parameters\n",
    "    experiment = Experiment(custom_params)\n",
    "    \n",
    "    # Run the simulation with the custom experiment\n",
    "    env = simpy.Environment()\n",
    "    rehab_unit = RehabilitationUnit(env, experiment)\n",
    "    model = AcuteStrokeUnit(env, experiment, rehab_unit)\n",
    "    model.run()\n",
    "    env.run(until=experiment.params['results_collection_period'])\n",
    "    \n",
    "    # Print results to check\n",
    "    print(\"\\nSimulation completed.\")\n",
    "    print(f\"Total simulation time: {model.env.now:.2f} days\")\n",
    "    print(f\"Total patient arrivals: {model.total_arrivals}\")\n",
    "    for patient_type in model.patient_types.values():\n",
    "        print(f\"Total {patient_type.name} arrivals: {patient_type.count}\")\n",
    "    \n",
    "    # Return the number of total arrivals\n",
    "\n",
    "    total_arrivals = model.total_arrivals\n",
    "    final_occupancy = model.occupancy\n",
    "\n",
    "    return total_arrivals == final_occupancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e3c934ea-0722-4343-a978-d50097f96758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ev_4(large_number=M):\n",
    "    '''\n",
    "    All patient types apart from stroke-rehab patients\n",
    "    have have their mean length \n",
    "    of stay time set to $M$ a very large number\n",
    "    \n",
    "    Expected result: Only stroke patients depart the\n",
    "    model.\n",
    "    (assessed crudely with patient_count > occupancy),\n",
    "    and also from log - see manual testing notebook.\n",
    "    \n",
    "    Params:\n",
    "    -------\n",
    "    large_number: int\n",
    "        M a very large number \n",
    "    '''\n",
    "    # Define custom parameters\n",
    "    custom_params = {\n",
    "        'Stroke': {'Rehab': (7.4, 8.6), 'ESD': (large_number, 4.8), 'Other': (large_number, 8.7)},\n",
    "        'TIA': (large_number, 5.0),\n",
    "        'Complex Neurological': (large_number, 5.0),\n",
    "        'Other': (large_number, 5.2)\n",
    "    }\n",
    "    \n",
    "    # Create an Experiment instance with custom parameters\n",
    "    experiment = Experiment(custom_params)\n",
    "    \n",
    "    # Run the simulation with the custom experiment\n",
    "    env = simpy.Environment()\n",
    "    rehab_unit = RehabilitationUnit(env, experiment)\n",
    "    model = AcuteStrokeUnit(env, experiment, rehab_unit)\n",
    "    model.run()\n",
    "    env.run(until=experiment.params['results_collection_period'])\n",
    "    \n",
    "    # Print results to check\n",
    "    print(\"\\nSimulation completed.\")\n",
    "    print(f\"Total simulation time: {model.env.now:.2f} days\")\n",
    "    print(f\"Total patient arrivals: {model.total_arrivals}\")\n",
    "    for patient_type in model.patient_types.values():\n",
    "        print(f\"Total {patient_type.name} arrivals: {patient_type.count}\")\n",
    "    \n",
    "    # Return the number of total arrivals\n",
    "\n",
    "    total_arrivals = model.total_arrivals\n",
    "    final_occupancy = model.occupancy\n",
    "\n",
    "    assert total_arrivals > final_occupancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bfe2ad38-b57a-4e9b-97c7-600ed72be4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ev_5(large_number=M):\n",
    "    '''\n",
    "    Complex Neuro, Other, have their rehab inter-arrival \n",
    "    time is set to $M$ a very large number\n",
    "    \n",
    "    Expected result: The only type of patient to arrive to the rehab model \n",
    "    is \"Stroke\". This is verified by the patient counts variables in the model.\n",
    "\n",
    "    Notes:\n",
    "    ------\n",
    "    This test will need to be modified when the hardcoded parameters\n",
    "    are migrated to the Experiment class. \n",
    "\n",
    "    Params:\n",
    "    -------\n",
    "    large_number: int\n",
    "        M a very large number \n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    bool: rehab_unit.stroke_count == rehab_unit.patient_count\n",
    "    '''\n",
    "    \n",
    "    experiment = Experiment({\n",
    "        'trace': False,  # Set to True if you want to see detailed logs\n",
    "        'rehab_stroke_iat': 21.8,\n",
    "        'rehab_neuro_iat': large_number,\n",
    "        'rehab_other_iat': large_number\n",
    "    })\n",
    "    env = simpy.Environment()\n",
    "    rehab_unit = RehabilitationUnit(env, experiment)\n",
    "    rehab_unit.run()\n",
    "    env.run(until=experiment.params['results_collection_period'])\n",
    "\n",
    "    # Print out stats collected\n",
    "    print(f\"Patient counts:\")\n",
    "    for patient_type, count in rehab_unit.patient_counts.items():\n",
    "        print(f\"  {patient_type}: {count}\")\n",
    "\n",
    "    print(f\"Total arrivals: {rehab_unit.total_arrivals}\")\n",
    "    \n",
    "    # Check if only Stroke patients arrived\n",
    "    assert rehab_unit.patient_counts['Stroke'] == rehab_unit.total_arrivals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ba5428e1-3f1d-4917-8f8e-482b10b1d3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ev_6(large_number=M):\n",
    "    '''\n",
    "    All patient types have their REHAB inter-arrival \n",
    "    time is set to $M$ a very large number\n",
    "    \n",
    "    Expected result: No patients arrive to the model\n",
    "    This is verified by the patient count variables in the model.\n",
    "\n",
    "    Params:\n",
    "    -------\n",
    "    large_number: int\n",
    "        M a very large number \n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    bool:rehab_unit.patient_count == 0\n",
    "    '''\n",
    "    # Create the simulation environment\n",
    "    experiment = Experiment({\n",
    "        'trace': True,  # Set to True if you want to see detailed logs\n",
    "        'rehab_stroke_iat': large_number,\n",
    "        'rehab_neuro_iat': large_number,\n",
    "        'rehab_other_iat': large_number\n",
    "    })\n",
    "    env = simpy.Environment()\n",
    "    rehab_unit = RehabilitationUnit(env, experiment)\n",
    "    rehab_unit.run()\n",
    "    env.run(until=experiment.params['results_collection_period'])\n",
    "\n",
    "    # Print out stats collected\n",
    "    print(f\"Patient counts:\")\n",
    "    for patient_type, count in rehab_unit.patient_counts.items():\n",
    "        print(f\"  {patient_type}: {count}\")\n",
    "\n",
    "    print(f\"Total arrivals: {rehab_unit.total_arrivals}\")\n",
    "    \n",
    "    print(f\"Total arrivals: {rehab_unit.total_arrivals}\")\n",
    "    \n",
    "    assert rehab_unit.total_arrivals == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7bba2871-c937-401f-8e90-2c6decb56d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ev_7(large_number=M):\n",
    "    '''\n",
    "    All patient types have have their mean length \n",
    "    of stay time in REHAB set to $M$ a very large number\n",
    "    \n",
    "    Expected result: No patients depart the rehab model \n",
    "    The occupancy of the model is equal to the no. patient arrivals\n",
    "    \n",
    "    Notes:\n",
    "    -----\n",
    "    This test will also need to be modified when TIA treatment is added\n",
    "    and tested when working in connection with the ASU.\n",
    "\n",
    "    Params:\n",
    "    -------\n",
    "    large_number: int\n",
    "        M a very large number \n",
    "    '''\n",
    "    # Create the simulation environment\n",
    "    experiment = Experiment({\n",
    "        'trace': True,  # Set to True if you want to see detailed logs\n",
    "        'rehab_stroke_esd_los_mean': large_number,\n",
    "        'rehab_stroke_other_los_mean': large_number,\n",
    "        'rehab_complex_neuro_los_mean': large_number,\n",
    "        'rehab_other_los_mean': large_number\n",
    "    })\n",
    "    env = simpy.Environment()\n",
    "    rehab_unit = RehabilitationUnit(env, experiment)\n",
    "    rehab_unit.run()\n",
    "    env.run(until=experiment.params['results_collection_period'])\n",
    "\n",
    "    # Print out stats collected\n",
    "    print(f\"Patient counts:\")\n",
    "    for patient_type, count in rehab_unit.patient_counts.items():\n",
    "        print(f\"  {patient_type}: {count}\")\n",
    "\n",
    "    print(f\"Total arrivals: {rehab_unit.total_arrivals}\")\n",
    "\n",
    "    print(f\"Total arrivals: {rehab_unit.total_arrivals}\")\n",
    "    \n",
    "    assert rehab_unit.total_arrivals == rehab_unit.occupancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ca0974da-79fd-418a-a2c9-ab06e07fcac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ev_8(large_number=M):\n",
    "    '''\n",
    "    All patient types have their AUS and REHAB inter-arrival \n",
    "    time is set to $M$ a very large number\n",
    "    \n",
    "    Expected result: No patients arrive to the model\n",
    "    This is verified by the patient count variables in the model.\n",
    "\n",
    "    Params:\n",
    "    -------\n",
    "    large_number: int\n",
    "        M a very large number \n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    bool:rehab_unit.patient_count == 0 and asu.patient_count == 0\n",
    "    '''\n",
    "   # Create the simulation environment\n",
    "    env = simpy.Environment()\n",
    "    \n",
    "    # Set all inter-arrival times to a large number\n",
    "    experiment_params = {\n",
    "        'run_length': 365,  # Run for 1 year\n",
    "        'trace': False,\n",
    "        'patient_types': {\n",
    "            'Stroke': {'interarrival_time': large_number},\n",
    "            'TIA': {'interarrival_time': large_number},\n",
    "            'Complex Neurological': {'interarrival_time': large_number},\n",
    "            'Other': {'interarrival_time': large_number}\n",
    "        },\n",
    "        'rehab_stroke_iat': large_number,\n",
    "        'rehab_neuro_iat': large_number,\n",
    "        'rehab_other_iat': large_number\n",
    "    }\n",
    "    \n",
    "    # Create experiment\n",
    "    experiment = Experiment(experiment_params)\n",
    "    \n",
    "    # Create models\n",
    "    rehab_unit = RehabilitationUnit(env, experiment)\n",
    "    asu = AcuteStrokeUnit(env, experiment, rehab_unit)\n",
    "    \n",
    "    # Start the ASU patient generators for each type of patient\n",
    "    asu.run()\n",
    "    rehab_unit.run()\n",
    "    \n",
    "    # Run the simulation\n",
    "    env.run(until=experiment.params['run_length'])\n",
    "\n",
    "    # Print out stats collected\n",
    "    print(f'ASU total arrivals: {asu.total_arrivals}')\n",
    "    print(f'Rehab total arrivals: {rehab_unit.total_arrivals}')\n",
    "    for patient_type, count in asu.patient_types.items():\n",
    "        print(f'ASU {patient_type} count: {count.count}')\n",
    "    print(f'Rehab patient counts: {rehab_unit.patient_counts}')\n",
    "    print(f'ASU occupancy: {asu.occupancy}')\n",
    "    print(f'Rehab occupancy: {rehab_unit.occupancy}')\n",
    "    \n",
    "    # Check if all patient counts are zero\n",
    "    asu_zero = all(pt.count == 0 for pt in asu.patient_types.values())\n",
    "    rehab_zero = all(count == 0 for count in rehab_unit.patient_counts.values())\n",
    "    \n",
    "    assert asu.total_arrivals == rehab_unit.total_arrivals == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0953988f-8e6e-466c-a9c5-cf90d8e1a9eb",
   "metadata": {},
   "source": [
    "## Run all automated tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1b742a16-1bd8-4631-b7f0-acc55cb497af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 25 items\n",
      "\n",
      "t_3b08eb41c6c348babb5152b25997efb1.py::test_result_processing_1[values0-rel_expected0-cum_expected0] \u001b[32mPASSED\u001b[0m\u001b[32m [  4%]\u001b[0m\n",
      "t_3b08eb41c6c348babb5152b25997efb1.py::test_result_processing_2[relative0-cum0-p_delay_expected0] \u001b[32mPASSED\u001b[0m\u001b[32m [  8%]\u001b[0m\n",
      "t_3b08eb41c6c348babb5152b25997efb1.py::test_results_collection_2 \u001b[32mPASSED\u001b[0m\u001b[32m                      [ 12%]\u001b[0m\n",
      "t_3b08eb41c6c348babb5152b25997efb1.py::test_results_collection_system \u001b[32mPASSED\u001b[0m\u001b[32m                 [ 16%]\u001b[0m\n",
      "t_3b08eb41c6c348babb5152b25997efb1.py::test_warm_up[365-1] \u001b[32mPASSED\u001b[0m\u001b[32m                            [ 20%]\u001b[0m\n",
      "t_3b08eb41c6c348babb5152b25997efb1.py::test_warm_up[1000-1] \u001b[32mPASSED\u001b[0m\u001b[32m                           [ 24%]\u001b[0m\n",
      "t_3b08eb41c6c348babb5152b25997efb1.py::test_single_run \u001b[32mPASSED\u001b[0m\u001b[32m                                [ 28%]\u001b[0m\n",
      "t_3b08eb41c6c348babb5152b25997efb1.py::test_random_number_set_1[0-False] \u001b[32mPASSED\u001b[0m\u001b[32m              [ 32%]\u001b[0m\n",
      "t_3b08eb41c6c348babb5152b25997efb1.py::test_random_number_set_1[1-False] \u001b[32mPASSED\u001b[0m\u001b[32m              [ 36%]\u001b[0m\n",
      "t_3b08eb41c6c348babb5152b25997efb1.py::test_random_number_set_1[2-False] \u001b[32mPASSED\u001b[0m\u001b[32m              [ 40%]\u001b[0m\n",
      "t_3b08eb41c6c348babb5152b25997efb1.py::test_random_number_set_1[101-False] \u001b[32mPASSED\u001b[0m\u001b[32m            [ 44%]\u001b[0m\n",
      "t_3b08eb41c6c348babb5152b25997efb1.py::test_random_number_set_1[42-False] \u001b[32mPASSED\u001b[0m\u001b[32m             [ 48%]\u001b[0m\n",
      "t_3b08eb41c6c348babb5152b25997efb1.py::test_random_number_set_2[0-False] \u001b[32mPASSED\u001b[0m\u001b[32m              [ 52%]\u001b[0m\n",
      "t_3b08eb41c6c348babb5152b25997efb1.py::test_random_number_set_2[1-False] \u001b[32mPASSED\u001b[0m\u001b[32m              [ 56%]\u001b[0m\n",
      "t_3b08eb41c6c348babb5152b25997efb1.py::test_random_number_set_2[2-False] \u001b[32mPASSED\u001b[0m\u001b[32m              [ 60%]\u001b[0m\n",
      "t_3b08eb41c6c348babb5152b25997efb1.py::test_random_number_set_2[101-False] \u001b[32mPASSED\u001b[0m\u001b[32m            [ 64%]\u001b[0m\n",
      "t_3b08eb41c6c348babb5152b25997efb1.py::test_random_number_set_2[42-False] \u001b[32mPASSED\u001b[0m\u001b[32m             [ 68%]\u001b[0m\n",
      "t_3b08eb41c6c348babb5152b25997efb1.py::test_lognormal_moments[128.79-267.51] \u001b[32mPASSED\u001b[0m\u001b[32m          [ 72%]\u001b[0m\n",
      "t_3b08eb41c6c348babb5152b25997efb1.py::test_lognormal_moments[50.0-2.0] \u001b[32mPASSED\u001b[0m\u001b[32m               [ 76%]\u001b[0m\n",
      "t_3b08eb41c6c348babb5152b25997efb1.py::test_lognormal_moments[10.5-1.0] \u001b[32mPASSED\u001b[0m\u001b[32m               [ 80%]\u001b[0m\n",
      "t_3b08eb41c6c348babb5152b25997efb1.py::test_ev_4 \u001b[32mPASSED\u001b[0m\u001b[32m                                      [ 84%]\u001b[0m\n",
      "t_3b08eb41c6c348babb5152b25997efb1.py::test_ev_5 \u001b[32mPASSED\u001b[0m\u001b[32m                                      [ 88%]\u001b[0m\n",
      "t_3b08eb41c6c348babb5152b25997efb1.py::test_ev_6 \u001b[32mPASSED\u001b[0m\u001b[32m                                      [ 92%]\u001b[0m\n",
      "t_3b08eb41c6c348babb5152b25997efb1.py::test_ev_7 \u001b[32mPASSED\u001b[0m\u001b[32m                                      [ 96%]\u001b[0m\n",
      "t_3b08eb41c6c348babb5152b25997efb1.py::test_ev_8 \u001b[32mPASSED\u001b[0m\u001b[32m                                      [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m======================================== \u001b[32m\u001b[1m25 passed\u001b[0m\u001b[32m in 1.82s\u001b[0m\u001b[32m ========================================\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.OK: 0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipytest.run(\"-vv\", \"--no-header\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf18dc8-238c-43fd-be2e-c645aca8b21b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
